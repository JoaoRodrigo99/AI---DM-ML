{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kAMvy3WHF6-s"
      },
      "outputs": [],
      "source": [
        "# Data processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "\n",
        "# Visualization\n",
        "import seaborn as sb\n",
        "\n",
        "# Similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Other\n",
        "import math\n",
        "import random\n",
        "import sklearn\n",
        "from nltk.corpus import stopwords\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lJ2qz0tZGGed"
      },
      "outputs": [],
      "source": [
        "# Mounting colab drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XikBdUQcGxYr"
      },
      "outputs": [],
      "source": [
        "# path = '/content/drive/MyDrive/Anime Recommender NLP Based/data/anime_with_synopsis.csv'\n",
        "path = '../archive/anime_with_synopsis.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ETsD8xhrF6-w"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(path)\n",
        "#animelist_df = pd.read_csv('../archive/animelist.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dzrOE4IZF6-y"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MAL_ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Score</th>\n",
              "      <th>Genres</th>\n",
              "      <th>sypnopsis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Cowboy Bebop</td>\n",
              "      <td>8.78</td>\n",
              "      <td>Action, Adventure, Comedy, Drama, Sci-Fi, Space</td>\n",
              "      <td>In the year 2071, humanity has colonized sever...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
              "      <td>8.39</td>\n",
              "      <td>Action, Drama, Mystery, Sci-Fi, Space</td>\n",
              "      <td>other day, another bounty—such is the life of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>Trigun</td>\n",
              "      <td>8.24</td>\n",
              "      <td>Action, Sci-Fi, Adventure, Comedy, Drama, Shounen</td>\n",
              "      <td>Vash the Stampede is the man with a $$60,000,0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>Witch Hunter Robin</td>\n",
              "      <td>7.27</td>\n",
              "      <td>Action, Mystery, Police, Supernatural, Drama, ...</td>\n",
              "      <td>ches are individuals with special powers like ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>Bouken Ou Beet</td>\n",
              "      <td>6.98</td>\n",
              "      <td>Adventure, Fantasy, Shounen, Supernatural</td>\n",
              "      <td>It is the dark century and the people are suff...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MAL_ID                             Name Score  \\\n",
              "0       1                     Cowboy Bebop  8.78   \n",
              "1       5  Cowboy Bebop: Tengoku no Tobira  8.39   \n",
              "2       6                           Trigun  8.24   \n",
              "3       7               Witch Hunter Robin  7.27   \n",
              "4       8                   Bouken Ou Beet  6.98   \n",
              "\n",
              "                                              Genres  \\\n",
              "0    Action, Adventure, Comedy, Drama, Sci-Fi, Space   \n",
              "1              Action, Drama, Mystery, Sci-Fi, Space   \n",
              "2  Action, Sci-Fi, Adventure, Comedy, Drama, Shounen   \n",
              "3  Action, Mystery, Police, Supernatural, Drama, ...   \n",
              "4          Adventure, Fantasy, Shounen, Supernatural   \n",
              "\n",
              "                                           sypnopsis  \n",
              "0  In the year 2071, humanity has colonized sever...  \n",
              "1  other day, another bounty—such is the life of ...  \n",
              "2  Vash the Stampede is the man with a $$60,000,0...  \n",
              "3  ches are individuals with special powers like ...  \n",
              "4  It is the dark century and the people are suff...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vnEN8fbxF6-0"
      },
      "outputs": [],
      "source": [
        "#animelist_df = animelist_df.groupby('user_id')\n",
        "#animelist_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ArLricR0F6-2"
      },
      "outputs": [],
      "source": [
        "df[\"sypnopsis\"] = df[\"sypnopsis\"].fillna(\"\")\n",
        "\n",
        "#drop all rows that have a null synopsis\n",
        "df = df[df[\"sypnopsis\"] != \"\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FXmGDDGeF6-4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 16206 entries, 0 to 16213\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   MAL_ID     16206 non-null  int64 \n",
            " 1   Name       16206 non-null  object\n",
            " 2   Score      16206 non-null  object\n",
            " 3   Genres     16206 non-null  object\n",
            " 4   sypnopsis  16206 non-null  object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 759.7+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JDpqkx0AF6-5"
      },
      "outputs": [],
      "source": [
        "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
        "corpus = df['sypnopsis']\n",
        "tfidf_matrix = tf.fit_transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3qRqa1YnF6-6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "x64T6kxJF6-8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Boruto: Naruto Next Generations\n",
            "Naruto: Shippuuden\n",
            "Naruto: Shippuuden Movie 6 - Road to Ninja\n",
            "Naruto: Shippuuden Movie 4 - The Lost Tower\n",
            "Boruto: Naruto the Movie\n",
            "Naruto: Dai Katsugeki!! Yuki Hime Shinobu Houjou Dattebayo! - Konoha no Sato no Dai Undoukai\n",
            "Naruto: Shippuuden - Shippuu! \"Konoha Gakuen\" Den\n",
            "Naruto SD: Rock Lee no Seishun Full-Power Ninden\n",
            "The Last: Naruto the Movie\n",
            "Naruto: Shippuuden Movie 5 - Blood Prison\n"
          ]
        }
      ],
      "source": [
        "top_10_similar_indexes = list(pd.Series(cosine_sim[10]).sort_values(ascending = False).iloc[1:11].index)\n",
        "for i in top_10_similar_indexes:\n",
        "    print(df['Name'][i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13560                         One Piece Movie 14: Stampede\n",
              "2091        Scramble Wars: Tsuppashire! Genom Trophy Rally\n",
              "1425                                   Peter Pan no Bouken\n",
              "5997                                     One Piece Film: Z\n",
              "419                                      One Piece Movie 1\n",
              "14216                      Afraid To Be Cool / Raise Me Up\n",
              "3103     Naruto: Shippuuden - Shippuu! \"Konoha Gakuen\" Den\n",
              "1103                 One Piece: Mamore! Saigo no Dai Butai\n",
              "2315                                           Crusher Joe\n",
              "12445                                    Ku Pao Ying Xiong\n",
              "Name: Name, dtype: object"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load pre-trained Word2Vec model\n",
        "word2vec_model = Word2Vec.load('path/to/pretrained/word2vec/model')\n",
        "\n",
        "# Load SpaCy model for text preprocessing\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text.lower())\n",
        "    tokens = [token.lemma_ for token in doc if not token.is_punct and not token.is_stop]\n",
        "    return tokens\n",
        "\n",
        "def get_recommendations(query):\n",
        "    # Preprocess query\n",
        "    query_tokens = preprocess_text(query)\n",
        "\n",
        "    # Transform query tokens into word embeddings\n",
        "    query_embeddings = [word2vec_model.wv[token] for token in query_tokens if token in word2vec_model.wv]\n",
        "\n",
        "    if not query_embeddings:\n",
        "        return []\n",
        "\n",
        "    # Get document embeddings\n",
        "    document_embeddings = [word2vec_model.wv[token] for token in word2vec_model.wv.vocab]\n",
        "\n",
        "    # Calculate cosine similarities\n",
        "    cosine_similarities = cosine_similarity(query_embeddings, document_embeddings).flatten()\n",
        "\n",
        "    # Sort indices based on similarity scores\n",
        "    related_anime_indices = cosine_similarities.argsort()[::-1]\n",
        "\n",
        "    # Return recommended anime names\n",
        "    return [df['Name'].iloc[index] for index in related_anime_indices[:10]]\n",
        "\n",
        "\n",
        "get_recommendations(\"Cool animes about pirates\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hjK6PoT7F6-_"
      },
      "outputs": [],
      "source": [
        "def recommend(title, cosine_sim=cosine_sim):\n",
        "    recommended_anime = []\n",
        "    idx = df[df['Name'] == title].index[0]\n",
        "    top_10_similar_indexes = list(pd.Series(cosine_sim[idx]).sort_values(ascending = False).iloc[1:11].index)\n",
        "    # top_10_indexes = list(score_series.iloc[1:11].index)\n",
        "    for i in top_10_similar_indexes:\n",
        "        recommended_anime.append(list(df['Name'])[i])\n",
        "    return recommended_anime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "eE3HmwLcF6_A"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "index 0 is out of bounds for axis 0 with size 0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m recommend(\u001b[39m'\u001b[39;49m\u001b[39manime about pirates\u001b[39;49m\u001b[39m'\u001b[39;49m, cosine_sim)\n",
            "Cell \u001b[1;32mIn[12], line 3\u001b[0m, in \u001b[0;36mrecommend\u001b[1;34m(title, cosine_sim)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrecommend\u001b[39m(title, cosine_sim\u001b[39m=\u001b[39mcosine_sim):\n\u001b[0;32m      2\u001b[0m     recommended_anime \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m     idx \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39;49m\u001b[39mName\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39;49m title]\u001b[39m.\u001b[39;49mindex[\u001b[39m0\u001b[39;49m]\n\u001b[0;32m      4\u001b[0m     top_10_similar_indexes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(pd\u001b[39m.\u001b[39mSeries(cosine_sim[idx])\u001b[39m.\u001b[39msort_values(ascending \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m)\u001b[39m.\u001b[39miloc[\u001b[39m1\u001b[39m:\u001b[39m11\u001b[39m]\u001b[39m.\u001b[39mindex)\n\u001b[0;32m      5\u001b[0m     \u001b[39m# top_10_indexes = list(score_series.iloc[1:11].index)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\35191\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5320\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5317\u001b[0m \u001b[39mif\u001b[39;00m is_integer(key) \u001b[39mor\u001b[39;00m is_float(key):\n\u001b[0;32m   5318\u001b[0m     \u001b[39m# GH#44051 exclude bool, which would return a 2d ndarray\u001b[39;00m\n\u001b[0;32m   5319\u001b[0m     key \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mcast_scalar_indexer(key, warn_float\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m-> 5320\u001b[0m     \u001b[39mreturn\u001b[39;00m getitem(key)\n\u001b[0;32m   5322\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[0;32m   5323\u001b[0m     \u001b[39m# This case is separated from the conditional above to avoid\u001b[39;00m\n\u001b[0;32m   5324\u001b[0m     \u001b[39m# pessimization com.is_bool_indexer and ndim checks.\u001b[39;00m\n\u001b[0;32m   5325\u001b[0m     result \u001b[39m=\u001b[39m getitem(key)\n",
            "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ],
      "source": [
        "recommend('Tengen Toppa Gurren Lagann', cosine_sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OZn-LRy2F6_C"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MAL_ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Score</th>\n",
              "      <th>Genres</th>\n",
              "      <th>sypnopsis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6485</th>\n",
              "      <td>16067</td>\n",
              "      <td>Nagi no Asu kara</td>\n",
              "      <td>8.09</td>\n",
              "      <td>Drama, Fantasy, Romance</td>\n",
              "      <td>ong ago, all humans lived beneath the sea. How...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      MAL_ID              Name Score                   Genres  \\\n",
              "6485   16067  Nagi no Asu kara  8.09  Drama, Fantasy, Romance   \n",
              "\n",
              "                                              sypnopsis  \n",
              "6485  ong ago, all humans lived beneath the sea. How...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['Name'] == 'Nagi no Asu kara']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lERVWrHuF6_C"
      },
      "source": [
        "# Text Similarity"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "75qmYFMSF6_E"
      },
      "source": [
        "### Using Roberta Large Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2lMSjP2wKKUI"
      },
      "outputs": [],
      "source": [
        "#!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YNtMTdUuF6_F"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\35191\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "sGp2kdImF6_G"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer('stsb-roberta-large')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vlJC_e5uF6_G"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16206"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = df['sypnopsis'].tolist()\n",
        "len(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "zuHYncymi_Qf"
      },
      "outputs": [],
      "source": [
        "bert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZkVKHzK0F6_H"
      },
      "outputs": [],
      "source": [
        "corpus = df['sypnopsis'].tolist()\n",
        "# embeddings = model.encode(corpus, convert_to_tensor=True)\n",
        "# torch.save(embeddings, 'corpus_embeddings.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pxnGw-7wF6_I"
      },
      "outputs": [],
      "source": [
        "corpus_embeddings = torch.load('corpus_embeddings.pt', map_location=torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MAL_ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Score</th>\n",
              "      <th>Genres</th>\n",
              "      <th>sypnopsis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Cowboy Bebop</td>\n",
              "      <td>8.78</td>\n",
              "      <td>Action, Adventure, Comedy, Drama, Sci-Fi, Space</td>\n",
              "      <td>In the year 2071, humanity has colonized sever...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
              "      <td>8.39</td>\n",
              "      <td>Action, Drama, Mystery, Sci-Fi, Space</td>\n",
              "      <td>other day, another bounty—such is the life of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>Trigun</td>\n",
              "      <td>8.24</td>\n",
              "      <td>Action, Sci-Fi, Adventure, Comedy, Drama, Shounen</td>\n",
              "      <td>Vash the Stampede is the man with a $$60,000,0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>Witch Hunter Robin</td>\n",
              "      <td>7.27</td>\n",
              "      <td>Action, Mystery, Police, Supernatural, Drama, ...</td>\n",
              "      <td>ches are individuals with special powers like ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>Bouken Ou Beet</td>\n",
              "      <td>6.98</td>\n",
              "      <td>Adventure, Fantasy, Shounen, Supernatural</td>\n",
              "      <td>It is the dark century and the people are suff...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MAL_ID                             Name Score  \\\n",
              "0       1                     Cowboy Bebop  8.78   \n",
              "1       5  Cowboy Bebop: Tengoku no Tobira  8.39   \n",
              "2       6                           Trigun  8.24   \n",
              "3       7               Witch Hunter Robin  7.27   \n",
              "4       8                   Bouken Ou Beet  6.98   \n",
              "\n",
              "                                              Genres  \\\n",
              "0    Action, Adventure, Comedy, Drama, Sci-Fi, Space   \n",
              "1              Action, Drama, Mystery, Sci-Fi, Space   \n",
              "2  Action, Sci-Fi, Adventure, Comedy, Drama, Shounen   \n",
              "3  Action, Mystery, Police, Supernatural, Drama, ...   \n",
              "4          Adventure, Fantasy, Shounen, Supernatural   \n",
              "\n",
              "                                           sypnopsis  \n",
              "0  In the year 2071, humanity has colonized sever...  \n",
              "1  other day, another bounty—such is the life of ...  \n",
              "2  Vash the Stampede is the man with a $$60,000,0...  \n",
              "3  ches are individuals with special powers like ...  \n",
              "4  It is the dark century and the people are suff...  "
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "i-eHUSr6F6_I"
      },
      "outputs": [],
      "source": [
        "sentence = 'pirate'\n",
        "\n",
        "sentence_embedding = model.encode(sentence, convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "kMq76aBHqsKq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.3177,  1.0460,  0.5271,  ..., -0.2072, -0.3559, -0.8465])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "G5zWUUZjF6_J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: pirate\n",
            "\n",
            "Top 10 most similar sentences in corpus:\n",
            "Dr. Slump Movie 11: Dr. Mashirito & Abale-chan (Score: 0.4534)\n",
            "Fairy Tail Movie 2: Dragon Cry (Score: 0.4491)\n",
            "Straw Byururu (Score: 0.4210)\n",
            "Lupin III: Cagliostro no Shiro (Score: 0.4154)\n",
            "Ryuuichi Manga Gekijou Onbu Obake (Score: 0.4145)\n",
            "Nagagutsu wo Haita Neko no Bouken (Score: 0.4142)\n",
            "Dragon Quest: Abel Yuusha Densetsu (Score: 0.4131)\n",
            "Dakara Boku wa, H ga Dekinai. (Score: 0.4121)\n",
            "A New Journey (Score: 0.4099)\n",
            "Kamishibai Itazura Tanuki no Maki (Score: 0.4077)\n"
          ]
        }
      ],
      "source": [
        "top_k = 10\n",
        "cos_scores = util.pytorch_cos_sim(sentence_embedding, corpus_embeddings)[0]\n",
        "\n",
        "top_results = np.argpartition(-cos_scores.cpu(), range(top_k))[0:top_k]\n",
        "\n",
        "print(\"\\n\\n======================\\n\\n\")\n",
        "print(\"Query:\", sentence)\n",
        "print(\"\\nTop 10 most similar sentences in corpus:\")\n",
        "for idx in top_results[0:top_k]:\n",
        "    title_name = df[df['sypnopsis'] == corpus[idx].strip()]['Name'].values[0]\n",
        "    print(title_name, \"(Score: %.4f)\" % (cos_scores[idx]))\n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv1uAt9gThhV"
      },
      "source": [
        "# Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "byDy1PqSF6_J"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\35191\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\35191\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4H-VQqYqVI6A"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\35191\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "OlGAlqFAbMqZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     C:\\Users\\35191\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('maxent_ne_chunker')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "a054zzrycF2J"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to\n",
            "[nltk_data]     C:\\Users\\35191\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "X6JyqmTrUuZr"
      },
      "outputs": [],
      "source": [
        "def preprocess(sent):\n",
        "  sent = nltk.word_tokenize(sent)\n",
        "  sent = nltk.pos_tag(sent)\n",
        "  return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7Zvf2KFrUzN0"
      },
      "outputs": [],
      "source": [
        "text = df.sample(1)['sypnopsis'].values[0]\n",
        "sent = preprocess(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "uMnMy5ICU2Xc"
      },
      "outputs": [],
      "source": [
        "pattern = 'NP : {<DT>?<JJ>*<NN>}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "sIZVkAyqVNbN"
      },
      "outputs": [],
      "source": [
        "cp = nltk.RegexpParser(pattern)\n",
        "cs = cp.parse(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-_9BbOyyZf2E"
      },
      "outputs": [],
      "source": [
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "from nltk import ne_chunk\n",
        "from pprint import pprint\n",
        "iob_tagged = tree2conlltags(cs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ZQ7A-NW3ZrlH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(S\n",
            "  monkey/NN\n",
            "  tricks/VBZ\n",
            "  a/DT\n",
            "  crab/NN\n",
            "  and/CC\n",
            "  steals/NNS\n",
            "  his/PRP$\n",
            "  food/NN\n",
            "  ./.)\n"
          ]
        }
      ],
      "source": [
        "ne_tree = ne_chunk(pos_tag(word_tokenize(text)))\n",
        "print(ne_tree)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ly52suO9hmA6"
      },
      "source": [
        "#Topic Extraction"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_4SrHGQAkn4r"
      },
      "source": [
        "# Keyword Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "C0CexzPrlzpp"
      },
      "outputs": [],
      "source": [
        "#!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "IxeWPBbxmNZX"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "def get_hotwords(text,n):\n",
        "    result = []\n",
        "    pos_tag = ['PROPN', 'ADJ', 'NOUN'] \n",
        "    doc = nlp(text.lower()) \n",
        "    for token in doc:\n",
        "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
        "            continue\n",
        "        if(token.pos_ in pos_tag):\n",
        "            result.append(token.text)\n",
        "    output = set(result)\n",
        "    most_common_list = Counter(output).most_common(n)\n",
        "    return most_common_list\n",
        "\n",
        "#output = set(get_hotwords(new_text))\n",
        "#most_common_list = Counter(output).most_common(10)\n",
        "\n",
        "# most_common_list = get_hotwords(new_text, 10)\n",
        "\n",
        "# for item in most_common_list:\n",
        "#   print(item[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfJWjSnsmxik"
      },
      "outputs": [],
      "source": [
        "\n",
        "  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EYPLKChOkrF1"
      },
      "source": [
        "# Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9BR96OIhstY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
