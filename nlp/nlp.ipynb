{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kAMvy3WHF6-s"
      },
      "outputs": [],
      "source": [
        "# Data processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats\n",
        "\n",
        "# Visualization\n",
        "import seaborn as sb\n",
        "\n",
        "# Similarity\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Other\n",
        "import math\n",
        "import random\n",
        "import sklearn\n",
        "from nltk.corpus import stopwords\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lJ2qz0tZGGed"
      },
      "outputs": [],
      "source": [
        "# Mounting colab drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XikBdUQcGxYr"
      },
      "outputs": [],
      "source": [
        "# path = '/content/drive/MyDrive/Anime Recommender NLP Based/data/anime_with_synopsis.csv'\n",
        "path = '../archive/anime_with_synopsis.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ETsD8xhrF6-w"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(path)\n",
        "#animelist_df = pd.read_csv('../archive/animelist.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "dzrOE4IZF6-y"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MAL_ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Score</th>\n",
              "      <th>Genres</th>\n",
              "      <th>sypnopsis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Cowboy Bebop</td>\n",
              "      <td>8.78</td>\n",
              "      <td>Action, Adventure, Comedy, Drama, Sci-Fi, Space</td>\n",
              "      <td>In the year 2071, humanity has colonized sever...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>Cowboy Bebop: Tengoku no Tobira</td>\n",
              "      <td>8.39</td>\n",
              "      <td>Action, Drama, Mystery, Sci-Fi, Space</td>\n",
              "      <td>other day, another bounty—such is the life of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>Trigun</td>\n",
              "      <td>8.24</td>\n",
              "      <td>Action, Sci-Fi, Adventure, Comedy, Drama, Shounen</td>\n",
              "      <td>Vash the Stampede is the man with a $$60,000,0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>Witch Hunter Robin</td>\n",
              "      <td>7.27</td>\n",
              "      <td>Action, Mystery, Police, Supernatural, Drama, ...</td>\n",
              "      <td>ches are individuals with special powers like ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>Bouken Ou Beet</td>\n",
              "      <td>6.98</td>\n",
              "      <td>Adventure, Fantasy, Shounen, Supernatural</td>\n",
              "      <td>It is the dark century and the people are suff...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MAL_ID                             Name Score  \\\n",
              "0       1                     Cowboy Bebop  8.78   \n",
              "1       5  Cowboy Bebop: Tengoku no Tobira  8.39   \n",
              "2       6                           Trigun  8.24   \n",
              "3       7               Witch Hunter Robin  7.27   \n",
              "4       8                   Bouken Ou Beet  6.98   \n",
              "\n",
              "                                              Genres  \\\n",
              "0    Action, Adventure, Comedy, Drama, Sci-Fi, Space   \n",
              "1              Action, Drama, Mystery, Sci-Fi, Space   \n",
              "2  Action, Sci-Fi, Adventure, Comedy, Drama, Shounen   \n",
              "3  Action, Mystery, Police, Supernatural, Drama, ...   \n",
              "4          Adventure, Fantasy, Shounen, Supernatural   \n",
              "\n",
              "                                           sypnopsis  \n",
              "0  In the year 2071, humanity has colonized sever...  \n",
              "1  other day, another bounty—such is the life of ...  \n",
              "2  Vash the Stampede is the man with a $$60,000,0...  \n",
              "3  ches are individuals with special powers like ...  \n",
              "4  It is the dark century and the people are suff...  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "vnEN8fbxF6-0"
      },
      "outputs": [],
      "source": [
        "#animelist_df = animelist_df.groupby('user_id')\n",
        "#animelist_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ArLricR0F6-2"
      },
      "outputs": [],
      "source": [
        "df[\"sypnopsis\"] = df[\"sypnopsis\"].fillna(\"\")\n",
        "\n",
        "#drop all rows that have a null synopsis\n",
        "df = df[df[\"sypnopsis\"] != \"\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FXmGDDGeF6-4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 16206 entries, 0 to 16213\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   MAL_ID     16206 non-null  int64 \n",
            " 1   Name       16206 non-null  object\n",
            " 2   Score      16206 non-null  object\n",
            " 3   Genres     16206 non-null  object\n",
            " 4   sypnopsis  16206 non-null  object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 759.7+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "JDpqkx0AF6-5"
      },
      "outputs": [],
      "source": [
        "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
        "corpus = df['sypnopsis']\n",
        "tfidf_matrix = tf.fit_transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "3qRqa1YnF6-6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "x64T6kxJF6-8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Boruto: Naruto Next Generations\n",
            "Naruto: Shippuuden\n",
            "Naruto: Shippuuden Movie 6 - Road to Ninja\n",
            "Naruto: Shippuuden Movie 4 - The Lost Tower\n",
            "Boruto: Naruto the Movie\n",
            "Naruto: Dai Katsugeki!! Yuki Hime Shinobu Houjou Dattebayo! - Konoha no Sato no Dai Undoukai\n",
            "Naruto: Shippuuden - Shippuu! \"Konoha Gakuen\" Den\n",
            "Naruto SD: Rock Lee no Seishun Full-Power Ninden\n",
            "The Last: Naruto the Movie\n",
            "Naruto: Shippuuden Movie 5 - Blood Prison\n"
          ]
        }
      ],
      "source": [
        "top_10_similar_indexes = list(pd.Series(cosine_sim[10]).sort_values(ascending = False).iloc[1:11].index)\n",
        "for i in top_10_similar_indexes:\n",
        "    print(df['Name'][i])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hjK6PoT7F6-_"
      },
      "outputs": [],
      "source": [
        "def recommend(title, cosine_sim=cosine_sim):\n",
        "    recommended_anime = []\n",
        "    idx = df[df['Name'] == title].index[0]\n",
        "    top_10_similar_indexes = list(pd.Series(cosine_sim[idx]).sort_values(ascending = False).iloc[1:11].index)\n",
        "    # top_10_indexes = list(score_series.iloc[1:11].index)\n",
        "    for i in top_10_similar_indexes:\n",
        "        recommended_anime.append(list(df['Name'])[i])\n",
        "    return recommended_anime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "eE3HmwLcF6_A"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Nagisa',\n",
              " 'Tengen Toppa Gurren Lagann: Ore no Gurren wa Pikka-Pika!!',\n",
              " 'Tengen Toppa Gurren Lagann: Mitee Mono wa Miteen da!!',\n",
              " 'Nagi no Asu kara',\n",
              " 'Blue Remains',\n",
              " 'Muv-Luv Alternative: Total Eclipse',\n",
              " 'Geisters: Fractions of the Earth',\n",
              " 'Shinkai no Kantai: Submarine 707',\n",
              " 'Yuurei Yashiki',\n",
              " 'Berserk: Ougon Jidai-hen I - Haou no Tamago']"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "recommend('Tengen Toppa Gurren Lagann', cosine_sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "OZn-LRy2F6_C"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MAL_ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Score</th>\n",
              "      <th>Genres</th>\n",
              "      <th>sypnopsis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6485</th>\n",
              "      <td>16067</td>\n",
              "      <td>Nagi no Asu kara</td>\n",
              "      <td>8.09</td>\n",
              "      <td>Drama, Fantasy, Romance</td>\n",
              "      <td>ong ago, all humans lived beneath the sea. How...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      MAL_ID              Name Score                   Genres  \\\n",
              "6485   16067  Nagi no Asu kara  8.09  Drama, Fantasy, Romance   \n",
              "\n",
              "                                              sypnopsis  \n",
              "6485  ong ago, all humans lived beneath the sea. How...  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[df['Name'] == 'Nagi no Asu kara']"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lERVWrHuF6_C"
      },
      "source": [
        "# Text Similarity"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "75qmYFMSF6_E"
      },
      "source": [
        "### Using Roberta Large Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "2lMSjP2wKKUI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.28.1)\n",
            "Requirement already satisfied: tqdm in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (2.0.0)\n",
            "Requirement already satisfied: torchvision in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers) (0.14.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.11.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.4.0)\n",
            "Requirement already satisfied: requests in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\35191\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\35191\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.13.3)\n",
            "Requirement already satisfied: click in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "#!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "YNtMTdUuF6_F"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "sGp2kdImF6_G"
      },
      "outputs": [],
      "source": [
        "model = SentenceTransformer('stsb-roberta-large')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "vlJC_e5uF6_G"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "16206"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = df['sypnopsis'].tolist()\n",
        "len(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "zuHYncymi_Qf"
      },
      "outputs": [],
      "source": [
        "bert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ZkVKHzK0F6_H"
      },
      "outputs": [],
      "source": [
        "corpus = df['sypnopsis'].tolist()\n",
        "# embeddings = model.encode(corpus, convert_to_tensor=True)\n",
        "# torch.save(embeddings, 'corpus_embeddings.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "pxnGw-7wF6_I"
      },
      "outputs": [],
      "source": [
        "corpus_embeddings = torch.load('corpus_embeddings.pt', map_location=torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "i-eHUSr6F6_I"
      },
      "outputs": [],
      "source": [
        "sentence = 'Naruto Uzumaki'\n",
        "\n",
        "sentence_embedding = model.encode(sentence, convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "kMq76aBHqsKq"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.5698, -1.0850,  0.1022,  ..., -1.2083, -0.8890,  0.2651])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "G5zWUUZjF6_J"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: Naruto Uzumaki\n",
            "\n",
            "Top 10 most similar sentences in corpus:\n",
            "Shin Koihime†Musou: Otome Tairan - Gakuensai da yo! Zenin Shuugou no Koto (Score: 0.6242)\n",
            "Time Ranger Cesar Boy no Bouken: Roma Teikoku-hen (Score: 0.6239)\n",
            "Yuuto-kun ga Iku Movie (Score: 0.6220)\n",
            "Midori no Makibao Compilation OVA (Score: 0.6177)\n",
            "Yuuki Yuuna wa Yuusha de Aru: Dai Mankai no Shou (Score: 0.6072)\n",
            "Mashin Eiyuuden Wataru: Soukaizan Eiyuu Densetsu (Score: 0.5904)\n",
            "Gochuumon wa Usagi Desu ka? Bloom (Score: 0.5857)\n",
            "Goku Sayonara Zetsubou Sensei (Score: 0.5822)\n",
            "Goku Sayonara Zetsubou Sensei (Score: 0.5822)\n",
            "Mushi no Tsubuyaki (Score: 0.5765)\n",
            "Hana no Asukagumi! 2: Lonely Cats Battle Royale (Score: 0.5753)\n",
            "Saru Kani Gassen (1927) (Score: 0.5704)\n",
            "Muddy Water (Score: 0.5691)\n",
            "Dreams (Score: 0.5683)\n",
            "Sayonara Gokko (Score: 0.5674)\n",
            "Minegishi-san wa Ootsu-kun ni Tabesasetai (Score: 0.5649)\n",
            "Chiisai Aki Mitsuketa (1982) (Score: 0.5638)\n",
            "Furusato no Gogatsu (Score: 0.5616)\n",
            "Kazaguruma (1996) (Score: 0.5559)\n",
            "Pipi Tobenai Hotaru (Score: 0.5526)\n"
          ]
        }
      ],
      "source": [
        "top_k = 20\n",
        "cos_scores = util.pytorch_cos_sim(sentence_embedding, corpus_embeddings)[0]\n",
        "\n",
        "top_results = np.argpartition(-cos_scores.cpu(), range(top_k))[0:top_k]\n",
        "\n",
        "print(\"\\n\\n======================\\n\\n\")\n",
        "print(\"Query:\", sentence)\n",
        "print(\"\\nTop 10 most similar sentences in corpus:\")\n",
        "for idx in top_results[0:top_k]:\n",
        "    title_name = df[df['sypnopsis'] == corpus[idx].strip()]['Name'].values[0]\n",
        "    print(title_name, \"(Score: %.4f)\" % (cos_scores[idx]))\n",
        "    "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Tv1uAt9gThhV"
      },
      "source": [
        "# Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "byDy1PqSF6_J"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\35191\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\35191\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "4H-VQqYqVI6A"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\35191\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "OlGAlqFAbMqZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     C:\\Users\\35191\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('maxent_ne_chunker')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "a054zzrycF2J"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to\n",
            "[nltk_data]     C:\\Users\\35191\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\words.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "X6JyqmTrUuZr"
      },
      "outputs": [],
      "source": [
        "def preprocess(sent):\n",
        "  sent = nltk.word_tokenize(sent)\n",
        "  sent = nltk.pos_tag(sent)\n",
        "  return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "7Zvf2KFrUzN0"
      },
      "outputs": [],
      "source": [
        "text = df.sample(1)['sypnopsis'].values[0]\n",
        "sent = preprocess(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "uMnMy5ICU2Xc"
      },
      "outputs": [],
      "source": [
        "pattern = 'NP : {<DT>?<JJ>*<NN>}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "sIZVkAyqVNbN"
      },
      "outputs": [],
      "source": [
        "cp = nltk.RegexpParser(pattern)\n",
        "cs = cp.parse(sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "-_9BbOyyZf2E"
      },
      "outputs": [],
      "source": [
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "from nltk import ne_chunk\n",
        "from pprint import pprint\n",
        "iob_tagged = tree2conlltags(cs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "ZQ7A-NW3ZrlH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(S\n",
            "  own/JJ\n",
            "  is/VBZ\n",
            "  attacked/VBN\n",
            "  by/IN\n",
            "  a/DT\n",
            "  deadly/JJ\n",
            "  creature/NN\n",
            "  ,/,\n",
            "  it/PRP\n",
            "  can/MD\n",
            "  only/RB\n",
            "  be/VB\n",
            "  stopped/VBN\n",
            "  with/IN\n",
            "  the/DT\n",
            "  (ORGANIZATION Dragon/NNP Blade/NNP)\n",
            "  ./.\n",
            "  The/DT\n",
            "  one/CD\n",
            "  person/NN\n",
            "  who/WP\n",
            "  knows/VBZ\n",
            "  where/WRB\n",
            "  the/DT\n",
            "  blade/NN\n",
            "  is/VBZ\n",
            "  wo/MD\n",
            "  n't/RB\n",
            "  tell/VB\n",
            "  (PERSON Lang/NNP)\n",
            "  ,/,\n",
            "  and/CC\n",
            "  even/RB\n",
            "  if/IN\n",
            "  he/PRP\n",
            "  did/VBD\n",
            "  ,/,\n",
            "  untold/JJ\n",
            "  peril/NN\n",
            "  will/MD\n",
            "  fall/VB\n",
            "  on/IN\n",
            "  anyone/NN\n",
            "  who/WP\n",
            "  dares/VBZ\n",
            "  to/TO\n",
            "  find/VB\n",
            "  this/DT\n",
            "  legendary/JJ\n",
            "  weapon/NN\n",
            "  ./.\n",
            "  (/(\n",
            "  (PERSON Source/NN)\n",
            "  :/:\n",
            "  AniDB/NNP\n",
            "  )/))\n"
          ]
        }
      ],
      "source": [
        "ne_tree = ne_chunk(pos_tag(word_tokenize(text)))\n",
        "print(ne_tree)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ly52suO9hmA6"
      },
      "source": [
        "#Topic Extraction"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_4SrHGQAkn4r"
      },
      "source": [
        "# Keyword Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "C0CexzPrlzpp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.28.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\35191\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (23.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: colorama in c:\\users\\35191\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\35191\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "#!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "IxeWPBbxmNZX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "learning\n",
            "score\n",
            "precision\n",
            "tag\n",
            "performance\n",
            "machine\n",
            "prediction\n",
            "correct\n",
            "match\n",
            "example\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "def get_hotwords(text,n):\n",
        "    result = []\n",
        "    pos_tag = ['PROPN', 'ADJ', 'NOUN'] \n",
        "    doc = nlp(text.lower()) \n",
        "    for token in doc:\n",
        "        if(token.text in nlp.Defaults.stop_words or token.text in punctuation):\n",
        "            continue\n",
        "        if(token.pos_ in pos_tag):\n",
        "            result.append(token.text)\n",
        "    output = set(result)\n",
        "    most_common_list = Counter(output).most_common(n)\n",
        "    return most_common_list\n",
        "\n",
        "#output = set(get_hotwords(new_text))\n",
        "#most_common_list = Counter(output).most_common(10)\n",
        "\n",
        "most_common_list = get_hotwords(new_text, 10)\n",
        "\n",
        "for item in most_common_list:\n",
        "  print(item[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "AfJWjSnsmxik"
      },
      "outputs": [],
      "source": [
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChzatFu-oeOO"
      },
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EYPLKChOkrF1"
      },
      "source": [
        "# Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9BR96OIhstY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
